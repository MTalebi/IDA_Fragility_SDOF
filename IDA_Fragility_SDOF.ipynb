{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4632b1b8-1921-4a5f-93dc-5d201a15d4f4",
   "metadata": {},
   "source": [
    "# Incremental Dynamic Analysis (IDA) and Fragility Curve for a Nonlinear SDOF System\n",
    "\n",
    "This notebook performs an Incremental Dynamic Analysis (IDA) on a single-degree-of-freedom (SDOF) system with nonlinear properties using FEMA P695 far-field ground motions from NGA-West2. For each ground motion record, the model is scaled from 0.05g to 2.0g (in increments of 0.05g), the maximum acceleration response is recorded, and collapse is determined based on a predefined collapse deformation. Using these results, the code constructs both IDA curves and a fragility curve (probability of collapse vs intensity measure). Rayleigh damping is applied to achieve a 5% damping ratio.\n",
    "\n",
    "The code is modular and organized into functions for:\n",
    "\n",
    "- Reading ground motion records\n",
    "- Building the SDOF model\n",
    "- Running the dynamic analysis for a given intensity\n",
    "- Processing results to build IDA and fragility curves\n",
    "\n",
    "Author: **Mohammad Talebi-Kalaleh** (<talebika@ualberta.ca>)\n",
    "\n",
    "Feel free to contact me for inquiries.\n",
    "\n",
    "See the README for further details on capabilities and citation information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3dd7e8-1d7e-4dd0-9f40-d843ab6c0cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import openseespy.opensees as ops\n",
    "import glob\n",
    "\n",
    "# -----------------------------\n",
    "# Global SDOF Properties (randomized for this example)\n",
    "# -----------------------------\n",
    "np.random.seed(0)  # for reproducibility\n",
    "\n",
    "# Define fundamental period and compute stiffness\n",
    "T = np.random.uniform(0.5, 1.5)        # fundamental period in seconds\n",
    "m = 1.0                                # mass\n",
    "omega = 2 * math.pi / T                # circular frequency\n",
    "K = m * (omega ** 2)                   # stiffness\n",
    "\n",
    "# Define yield strength and post-yield ratio\n",
    "Fy = np.random.uniform(0.3, 0.6) * 9.81 * m   # yield force (N)\n",
    "post_yield_ratio = np.random.uniform(0.02, 0.10)  # post-yield stiffness ratio\n",
    "\n",
    "# Define collapse force (a factor of Fy)\n",
    "collapse_factor = np.random.uniform(1.2, 2.0)   \n",
    "F_collapse = collapse_factor * Fy               \n",
    "\n",
    "print(f\"SDOF Properties: T={T:.2f}s, K={K:.1f} N/m, Fy={Fy:.2f} N, postYieldRatio={post_yield_ratio:.3f}, F_collapse={F_collapse:.2f} N\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a4d94e-df3d-4da8-bcce-5d5b054e1f6a",
   "metadata": {},
   "source": [
    "## Function Definitions\n",
    "\n",
    "Below are the functions that perform each part of the analysis. They are organized into:\n",
    "\n",
    "1. **Rayleigh Damping Coefficients**: Computes the Rayleigh damping coefficients to achieve a target damping ratio.\n",
    "2. **Ground Motion Reader**: Reads a ground motion file in the NGA-West2 (.AT2) format.\n",
    "3. **Dynamic Analysis**: Builds the SDOF model, applies the ground motion, runs the transient analysis, and returns the peak acceleration and collapse flag.\n",
    "4. **IDA and Fragility Analysis**: Loops over records and intensities to construct IDA curves and the collapse fragility curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c662bbd-197e-48d0-8d21-5c8cfb82bd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rayleigh_coefficients(zeta, freq1, freq2):\n",
    "    \"\"\"\n",
    "    Compute Rayleigh damping coefficients (alphaM, betaK) to achieve damping ratio zeta \n",
    "    at two circular frequencies: freq1 and freq2.\n",
    "    \"\"\"\n",
    "    w1, w2 = freq1, freq2\n",
    "    A = np.array([[0.5 * (1.0/w1), 0.5 * w1],\n",
    "                  [0.5 * (1.0/w2), 0.5 * w2]])\n",
    "    b = np.array([zeta, zeta])\n",
    "    alphaM, betaK = np.linalg.solve(A, b)\n",
    "    return alphaM, betaK\n",
    "\n",
    "# Compute Rayleigh coefficients for 5% damping at fundamental and a higher mode (5x fundamental frequency)\n",
    "damping_ratio = 0.05\n",
    "freq1 = omega\n",
    "freq2 = 5 * omega\n",
    "alphaM, betaK = rayleigh_coefficients(damping_ratio, freq1, freq2)\n",
    "\n",
    "def read_ground_motion(file_path):\n",
    "    \"\"\"\n",
    "    Reads a ground motion file in NGA-West2 .AT2 format.\n",
    "    Returns the acceleration time series (in g) and time step (dt in seconds).\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    dt = None\n",
    "    for line in lines:\n",
    "        if 'NPTS' in line and 'DT=' in line:\n",
    "            parts = line.strip().split(',')\n",
    "            for part in parts:\n",
    "                if 'DT=' in part:\n",
    "                    dt_str = part.split('=')[1].strip().split()[0]\n",
    "                    dt = float(dt_str)\n",
    "            break\n",
    "    header_lines = 0\n",
    "    for i, line in enumerate(lines):\n",
    "        if 'NPTS' in line and 'DT=' in line:\n",
    "            header_lines = i + 1\n",
    "            break\n",
    "    accel_data = []\n",
    "    for line in lines[header_lines:]:\n",
    "        vals = line.strip().split()\n",
    "        accel_data.extend([float(val) for val in vals])\n",
    "    accel_array = np.array(accel_data, dtype=float)\n",
    "    return accel_array, dt\n",
    "\n",
    "def run_sdo_analysis(accel_g, dt, scale_factor):\n",
    "    \"\"\"\n",
    "    Build and analyze the SDOF model in OpenSees for a given ground motion and scale factor.\n",
    "    Returns the peak absolute acceleration (in g) and a flag indicating collapse.\n",
    "    \"\"\"\n",
    "    ops.wipe()\n",
    "    ops.model('Basic', '-ndm', 1, '-ndf', 1)\n",
    "    ops.node(1, 0.0); ops.fix(1, 1)\n",
    "    ops.node(2, 0.0); ops.mass(2, m)\n",
    "    \n",
    "    # Define nonlinear material: Steel01 with bilinear behavior\n",
    "    matTag = 1\n",
    "    ops.uniaxialMaterial('Steel01', matTag, K, Fy, post_yield_ratio)\n",
    "    \n",
    "    # Define collapse by limiting deformation using MinMax material\n",
    "    yield_disp = Fy / K\n",
    "    if post_yield_ratio > 1e-6:\n",
    "        ult_disp = yield_disp + (F_collapse - Fy) / (K * post_yield_ratio)\n",
    "    else:\n",
    "        ult_disp = yield_disp if F_collapse <= Fy else 1e6\n",
    "    ops.uniaxialMaterial('MinMax', 2, matTag, '-max', ult_disp)\n",
    "    \n",
    "    ops.element('zeroLength', 1, 1, 2, '-mat', 2, '-dir', 1)\n",
    "    \n",
    "    # Apply Rayleigh damping\n",
    "    ops.rayleigh(alphaM, betaK, 0.0, 0.0)\n",
    "    \n",
    "    # Define ground motion: scale the input acceleration time series\n",
    "    g_accel = 9.81  \n",
    "    ops.timeSeries('Path', 1, '-dt', dt, '-values', *accel_g, '-factor', scale_factor * g_accel)\n",
    "    ops.pattern('UniformExcitation', 1, 1, '-accel', 1)\n",
    "    \n",
    "    # Set up transient analysis using Newmark integration\n",
    "    ops.integration('Newmark', 0.5, 0.25)\n",
    "    ops.system('Diagonal')\n",
    "    ops.numberer('Plain')\n",
    "    ops.constraints('Plain')\n",
    "    ops.algorithm('Newton', '-initial')\n",
    "    ops.test('NormDispIncr', 1e-7, 10, 3)\n",
    "    ops.analysis('Transient')\n",
    "    \n",
    "    n_steps = len(accel_g)\n",
    "    ok = ops.analyze(n_steps, dt)\n",
    "    peak_rel_acc = 0.0\n",
    "    collapse_occurred = False\n",
    "    if ok != 0:\n",
    "        collapse_occurred = True\n",
    "    \n",
    "    if ok == 0:\n",
    "        peak_rel_acc = 0.0\n",
    "        for step in range(n_steps):\n",
    "            rel_acc = ops.nodeAccel(2, 1)\n",
    "            if abs(rel_acc) > abs(peak_rel_acc):\n",
    "                peak_rel_acc = rel_acc\n",
    "            ops.analyze(1, dt)\n",
    "    else:\n",
    "        ops.wipeAnalysis()\n",
    "        ops.constraints('Plain')\n",
    "        ops.numberer('Plain')\n",
    "        ops.system('Diagonal')\n",
    "        ops.algorithm('Newton', '-initial')\n",
    "        ops.test('NormDispIncr', 1e-7, 10)\n",
    "        ops.analysis('Transient')\n",
    "        peak_rel_acc = 0.0\n",
    "        for step in range(n_steps):\n",
    "            if ops.analyze(1, dt) != 0:\n",
    "                collapse_occurred = True\n",
    "                break\n",
    "            rel_acc = ops.nodeAccel(2, 1)\n",
    "            if abs(rel_acc) > abs(peak_rel_acc):\n",
    "                peak_rel_acc = rel_acc\n",
    "    \n",
    "    abs_peak_acc = abs(peak_rel_acc) + (scale_factor * max(abs(accel_g)) * 9.81)\n",
    "    return abs_peak_acc / 9.81, collapse_occurred\n",
    "\n",
    "def perform_IDA_analysis(record_files, intensity_levels):\n",
    "    \"\"\"\n",
    "    Loops over all provided ground motion files and intensity levels.\n",
    "    Returns the IDA results and an array of collapse intensities for each record.\n",
    "    \"\"\"\n",
    "    ida_results = []\n",
    "    collapse_IMs = []\n",
    "    \n",
    "    for rec_file in record_files:\n",
    "        rec_name = rec_file.split('/')[-1]\n",
    "        accel_g, dt = read_ground_motion(rec_file)\n",
    "        orig_PGA = max(abs(accel_g))\n",
    "        record_IMs = []\n",
    "        record_max_acc = []\n",
    "        record_collapsed = False\n",
    "        collapse_im = None\n",
    "        \n",
    "        for IM in intensity_levels:\n",
    "            scale_factor = IM / orig_PGA\n",
    "            max_acc_response, collapsed = run_sdo_analysis(accel_g, dt, scale_factor)\n",
    "            record_IMs.append(IM)\n",
    "            record_max_acc.append(max_acc_response)\n",
    "            if collapsed and not record_collapsed:\n",
    "                record_collapsed = True\n",
    "                collapse_im = IM\n",
    "                break\n",
    "        if collapse_im is None:\n",
    "            collapse_im = 2.1\n",
    "        collapse_IMs.append(collapse_im)\n",
    "        ida_results.append({\n",
    "            'record': rec_name,\n",
    "            'IM': record_IMs,\n",
    "            'max_acc': record_max_acc,\n",
    "            'collapsed': record_collapsed\n",
    "        })\n",
    "        print(f\"Record {rec_name}: {'Collapsed at {:.2f}g'.format(collapse_im) if record_collapsed else 'No collapse up to 2.0g'}\")\n",
    "    \n",
    "    return ida_results, np.array(collapse_IMs)\n",
    "\n",
    "def compute_fragility(collapse_IMs, intensity_levels):\n",
    "    \"\"\"\n",
    "    Computes empirical collapse probabilities and fits a lognormal fragility curve\n",
    "    based on collapse intensities for each record.\n",
    "    Returns the intensity points, empirical probabilities, and fitted curve parameters.\n",
    "    \"\"\"\n",
    "    N_records = len(collapse_IMs)\n",
    "    prob_exceedance = []\n",
    "    for IM in intensity_levels:\n",
    "        count_collapsed = np.sum(collapse_IMs <= IM)\n",
    "        prob_exceedance.append(count_collapsed / N_records)\n",
    "    \n",
    "    # Fit lognormal fragility curve (using values capped at 2.0g for records not collapsing)\n",
    "    caps_for_fit = np.minimum(collapse_IMs, 2.0)\n",
    "    median_theta = math.exp(np.mean(np.log(caps_for_fit)))\n",
    "    beta = np.std(np.log(caps_for_fit))\n",
    "    \n",
    "    def fragility_cdf(IM):\n",
    "        return 0.5 * (1 + math.erf((math.log(IM/median_theta)) / (beta * math.sqrt(2))))\n",
    "    \n",
    "    IM_plot = np.linspace(0.0, 2.0, 100)\n",
    "    fragility_curve = [fragility_cdf(x) for x in IM_plot]\n",
    "    \n",
    "    return intensity_levels, prob_exceedance, IM_plot, fragility_curve, median_theta, beta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c31df50-0c5d-4d7a-8f7a-1d9a1e6d7b3c",
   "metadata": {},
   "source": [
    "## Main Execution\n",
    "\n",
    "The main part of the notebook executes the following steps:\n",
    "\n",
    "1. Read all ground motion records (assumed to be stored in a directory named `Records/` with `.AT2` files).\n",
    "2. Loop over intensity levels (0.05g to 2.0g) for each record and perform the dynamic analysis using `perform_IDA_analysis`.\n",
    "3. Compute the fragility curve based on the collapse intensities using `compute_fragility`.\n",
    "4. Plot the IDA curves and the fragility curve.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c21ce5-dc33-4aa2-9740-f3a6a57d9295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Execution\n",
    "\n",
    "# Define intensity levels (in g) from 0.05g to 2.0g\n",
    "intensity_levels = np.arange(0.05, 2.01, 0.05)\n",
    "\n",
    "# List ground motion files in the 'Records' directory\n",
    "record_files = glob.glob(\"Records/*.AT2\")\n",
    "if len(record_files) == 0:\n",
    "    print(\"No ground motion files found in the 'Records' directory.\")\n",
    "else:\n",
    "    # Perform IDA analysis for all records\n",
    "    ida_results, collapse_IMs = perform_IDA_analysis(record_files, intensity_levels)\n",
    "    \n",
    "    # Compute fragility data\n",
    "    IM_points, prob_exceedance, IM_plot, fragility_curve, median_theta, beta = compute_fragility(collapse_IMs, intensity_levels)\n",
    "    \n",
    "    # Plot IDA curves\n",
    "    plt.figure(figsize=(8,6))\n",
    "    for res in ida_results:\n",
    "        plt.plot(res['IM'], res['max_acc'], color='gray', linewidth=1, alpha=0.7)\n",
    "        if res['collapsed']:\n",
    "            collapse_idx = len(res['IM']) - 1\n",
    "            plt.plot(res['IM'][collapse_idx], res['max_acc'][collapse_idx], 'ro')\n",
    "    plt.xlabel('Intensity Measure (PGA, g)')\n",
    "    plt.ylabel('Peak SDOF Acceleration (g)')\n",
    "    plt.title('IDA Curves: Peak Acceleration vs. Intensity')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Fragility Curve\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.step(IM_points, prob_exceedance, where='post', label='Empirical Data', color='blue', linewidth=2, alpha=0.6)\n",
    "    plt.plot(IM_plot, fragility_curve, label=f'Lognormal Fit (θ={median_theta:.2f}g, β={beta:.2f})', color='black', linewidth=2)\n",
    "    plt.xlabel('Intensity Measure (PGA, g)')\n",
    "    plt.ylabel('Probability of Collapse')\n",
    "    plt.title('Fragility Curve for SDOF Collapse')\n",
    "    plt.ylim([0,1.05])\n",
    "    plt.xlim([0,2.0])\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
